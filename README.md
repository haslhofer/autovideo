# Auto Video / Short Story generation guided by Human Input

1)	With GPT-3 you can generate stories
2)	With DALL-E you can generate images from stories (Say hello to OpenAI's DALL-E, a bot that creates weird images from text (thenextweb.com)
3)	With WaveNet you can generate human voice from text

1+2+3 should allow us to generate video short stories.

Then we can use those clips within some reels experience (TikTok, …) and use the engagement as a proxy of “which stories work, which don’t”. 
Then use this to evolve the story (rinse & repeat) – basically explore / exploit algo.

My conjecture is that at some point the compute cost to generate the story is lower than the ad revenue you can generate per story, leading to positive returns at scale. Kind of like Project Summary - Docs (botto.com) on steroids

First examples of pseudo-generated videos (using wav2lip from Paddle Paddle) are here:

[Video 1 (on my YouTube channel)](https://www.youtube.com/watch?v=pE0BppJFylU)
[Video 2 (on my YouTube channel)](https://www.youtube.com/watch?v=_rvB5Tng_5k)
